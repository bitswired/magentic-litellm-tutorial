{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "Function calling is a powerful capability that allows LLMs to call external functions.\n",
    "\n",
    "These functions can do anything, such as call APIs, perform computations, and more.\n",
    "\n",
    "Magentic makes it really simple to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out some Pydantic warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from magentic import chatprompt, prompt, prompt_chain, SystemMessage, UserMessage, FunctionCall\n",
    "from magentic.chat_model.litellm_chat_model import LitellmChatModel\n",
    "from pydantic import BaseModel\n",
    "import requests\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define A Function To Get Realtime Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_weather(city_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves the weather information for a given city.\n",
    "\n",
    "    Args:\n",
    "        city_name (str): The name of the city for which to retrieve the weather information.\n",
    "\n",
    "    Returns:\n",
    "        str: The weather information for the specified city.\n",
    "    \"\"\"\n",
    "    base_url = f\"http://wttr.in/{city_name}?format=%C+%t\"\n",
    "    response = requests.get(base_url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling With Simple `@prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunctionCall(<function get_weather at 0x10e484680>, 'Lausanne')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Light rain +10°C'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@prompt(\n",
    "    \"Use the appropriate function to answer: {question}\",\n",
    "    functions=[get_weather],\n",
    "    model=LitellmChatModel(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "def answer(question: str) -> FunctionCall[str]: ...\n",
    "\n",
    "\n",
    "output = answer(\"What is the weather in Lausanne?\")\n",
    "print(output)\n",
    "output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling With `pompt_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in Lausanne is light rain with a temperature of +10°C.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@prompt_chain(\n",
    "    \"Use the appropriate function to answer: {question}\",\n",
    "    functions=[get_weather],\n",
    "    model=LitellmChatModel(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "def answer_chain(question: str) -> str: ...\n",
    "\n",
    "\n",
    "answer_chain(\"What is the weather in Lausanne?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling With `@chatprompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Light rain +10°C'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@chatprompt(\n",
    "    SystemMessage(\"You are a weather beast. Use the proper function to answer.\"),\n",
    "    UserMessage(\"{message}?\"),\n",
    "    model=LitellmChatModel(\"gpt-3.5-turbo\"),\n",
    "    functions=[get_weather],\n",
    ")\n",
    "def answer_chat(message: str) -> FunctionCall[str]: ...\n",
    "\n",
    "\n",
    "output = answer_chat(\"What is the weather in Lausanne?\")\n",
    "output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prometeeos-api-5W7JRlnu-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
