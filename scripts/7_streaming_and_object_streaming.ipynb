{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming And Object Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out some Pydantic warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from time import time\n",
    "from magentic import (\n",
    "    StreamedStr,\n",
    "    AsyncStreamedStr,\n",
    "    prompt,\n",
    ")\n",
    "from magentic.chat_model.litellm_chat_model import LitellmChatModel\n",
    "from pydantic import BaseModel\n",
    "from typing import AsyncIterable, Iterable\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "Streaming is a technique to receive partial results while generating.\n",
    "\n",
    "It's convenient to show something to the user instead of letting him wait for the entire response.\n",
    "\n",
    "With Magentic we can either stream synchronously or asynchronously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@prompt(\n",
    "    \"Tell me more about this topic stay concise: {topic}\",\n",
    "    model=LitellmChatModel(\"gpt-4-turbo\"),\n",
    ")\n",
    "def answer_sync(topic: str) -> StreamedStr: ...\n",
    "\n",
    "for chunk in  answer_sync(\"AI\"):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@prompt(\n",
    "    \"Tell me more about this topic stay concise: {topic}\",\n",
    "    model=LitellmChatModel(\"gpt-4-turbo\"),\n",
    ")\n",
    "async def answer_async(topic: str) -> AsyncStreamedStr: ...\n",
    "\n",
    "async for chunk in  await answer_async(\"AI\"):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Streaming\n",
    "\n",
    "Object streaming is a powerful technique for structured output generation.\n",
    "\n",
    "Instead of streaming chunk by chunk, we stream object by object.\n",
    "\n",
    "We wait for an entire object to be generated, we display, and keep going until the end.\n",
    "\n",
    "Agaim, with Magentic we can do it synchronously or asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous Object Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07s : name='Ms. Sushi' age=28 power='Water manipulation' enemies=['Wasabi Fiend', 'Soy Slasher']\n",
      "3.88s : name='Boss Burger' age=35 power='Super strength' enemies=['Veggie Vandal', 'Keto Crusader']\n",
      "4.97s : name='Taco Titan' age=30 power='Time manipulation' enemies=['Guac Ghoul', 'Salsa Spectre']\n",
      "5.83s : name='Pasta Paladin' age=29 power='Elasticity' enemies=['Alfredo Archmage', 'Noodle Nemesis']\n"
     ]
    }
   ],
   "source": [
    "class Superhero(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    power: str\n",
    "    enemies: list[str]\n",
    "\n",
    "\n",
    "@prompt(\"Create a Superhero team named {name}.\")\n",
    "def create_superhero_team(name: str) -> Iterable[Superhero]: ...\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "for hero in create_superhero_team(\"The Food Dudes\"):\n",
    "    print(f\"{time() - start_time:.2f}s : {hero}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Object Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.22s : name='Captain Carrot' age=30 power='Super Sight' enemies=['Junkfood Joker']\n",
      "3.90s : name='Broccoli Bolt' age=25 power='Super Speed' enemies=['Soda Slammer']\n",
      "4.64s : name='Steak Slater' age=35 power='Super Strength' enemies=['Vegan Vandal']\n",
      "5.67s : name='Tamale Twister' age=27 power='Weather Control' enemies=['Frozen Foodster']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Superhero(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    power: str\n",
    "    enemies: list[str]\n",
    "\n",
    "\n",
    "@prompt(\"Create a Superhero team named {name}.\")\n",
    "async def create_superhero_team(name: str) -> AsyncIterable[Superhero]: ...\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "async for hero in await create_superhero_team(\"The Food Dudes\"):\n",
    "    print(f\"{time() - start_time:.2f}s : {hero}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prometeeos-api-5W7JRlnu-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
